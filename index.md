## Stanley Mugisha

_Ph.D researcher in virtual reality and robotics at Ecole Centrale Nantes in France _ <br>

[Email](mailto:mugishastanleys@gmail.com) / [Website](https://mugishastanley.github.io/cv) / [LinkedIn](https://www.linkedin.com/in/stanley-mugisha/) / [GitHub](https://github.com/mugishastanley/) /

## üë©üèº‚Äçüíª Summary
I am a Ph.D researcher in virtual reality and robotics at Ecole Centrale Nantes in France. My experience spans more than three years in software development for collaborative robots and virtual reality. My research work has been in robot motion planning, control, and machine learning techniques for motion prediction in haptic applications, emphasizing user safety and security during human robot collaborative tasks. 

## üë©üèº‚Äçüíª Professional Experience
### ***Ph.D researcher CNRS, LS2N (France)*** _(Oct 2020 - Present)_ <br>
Worked in the Laboratoire des Sciences du Num√©rique √† Nantes, (LS2N) under the supervision of Prof. Damien Chablat and Prof. Christine Chevallereau. <br>
Project: @ [The lobbybot project](https://www.lobbybot.fr/) _(Oct 2020)_<br> . <br>
This project aims to develop an Intermittent Contact Interface for industrial use in the early stages of the design of materials for a car interior. The project is in partnership with Inria Rennes, Renault SAS, and Centre Lavallois de Ressources Technologiques Renault France, (Clarte) lab. <br>

Roles and responsibilities.
1.	Participated in continuous development and improvement by generating suggestions for the implementation of intermittent contact interface using an industrial robot for analysis of material of car interior and rehabilitation.
2.	Receiving feedback and suggestions about product development and enhancements from the industrial partners and stakeholders.
3.	Engaging in problem-solving activities to support teamwork.
4.	Coordination of the project development team which included fellow researchers and master's students.
5.	Conducted experimental design, evaluation, and tests of the developed software tools. 
 
  - **_Technologies used:_** C#, ROS, C++ , Matlab, python.
<br>

Achievements.
 
1.	Developed an intermittent contact interface(ICI) prototype based on the universal robot (UR5) to meet security requirements in the event of involuntary contact with the user. 
2.	Developed a visual representation system of the user's body in the virtual environment when the user is wearing a head mounted display.
3.	Developed real-time 3D tracking of a user's motion using HTC Vive sensors, making it possible to express the positions of each of the spatial components of the system (the virtual environment, robot, visualization system and motion capture systems) in the same frame.
4.	Modeled human motion in ROS based on sensor data. This was integrated with safety strategies to avoid human-robot collisions.
5.	Designed learning algorithms to predict user activity and detect their intention in a simulated and the real world. The prediction was based sensor data captured by htc vive trackers attached to the hands and analyzing eye gaze data to identify points of interest in the virtual environment. 
6.	Designed a multi-faceted prop to present the user with surfaces of different shapes and textures.
7.	Designed motion planning techniques for collision-free interaction with respect to motion constraints of the robot (workspace and speed limitations) and the dynamic objects in the environment, with the aim of generating the trajectories intended to overcome the inherent limitations of ICI. 
8.	Implemented pseudo-haptic feedback to increase the range of render-able shapes and materials. 
9.	Implemented feedback (visual, sound, haptic) to solve the problem of tracking a surface with the finger.
10.	Guided and worked with team members. These included an internship student working towards his final year master's thesis.
 
 
### ***Ph.D. Student. The University of Genova(Italy):*** _( Nov 2018- Sept 2020)_<br></hr> 
Worked in the department of DIME under the supervision of Prof. Matteo Zoppi and Prof. Rezia Molfino.

Project: Development of haptic interface for upper limb rehabilitation training. 
The scientific objective of the project was to improve the immersive experience of people with difficulty with upper limb motion through the provision of haptic feedback. The project aimed at improving the response time of a robot by anticipating the user's areas of interaction and moving the robot as early as possible while ensuring the safety of the user to overcome the inherent problems of haptic devices which include speed constraints and workspace limitations.
- **_Technologies used:_** Panda robot FCI , C#, ROS, C++.

Achievements: 
i.	Developed interactive virtual reality exergames for an upper limb rehabilitation program using the unity game engine. <br>
ii.	Performed a workspace and reachability analysis to determine the best position of the human and the virtual objects in the reachable workspace of the robot. <br>
iii.	Designed a Robot - VR interface for data exchange using the ROS framework (C++) and UDP sockets for real-time communication with the Franka control interface (FCI) of the panda Robot. <br>
iv.	Designed and implemented motion planning and control algorithms for real-time user interaction in the VR with the panda robot. <br>
v.	Designed and implemented safety protocols based on velocity modulation using the concept of safepoints. This was achieved by dividing the workspace into the robot workspace where the robot would move with high velocity and the human workspace where the robot would move at a low velocity robot while avoiding collisions with the user. <br>
vi.	Development and optimization of machine learning algorithms to predict the user motion based on sensor data and control the robot to improve the response time. <br>
 
Teaching support activities for the course of research methodology for students in master of robotics engineering academic year 2020/2021. <br>
Roles and Responsibilities  
i.	Assist the professor in delivering engaging, informative classroom activities which support the university curriculum.<br>
ii.	Deliver and supervise group activities, accurately assessing their impact on individual students.<br>
iii.	Maintain accurate records, including student achievements, progress, and attendance.<br>
iv.	Preparing teaching material.<br>

### **Assistant lecturer , Soroti University** Nov 2017 - Oct 2018. . 
Worked as Assistant lecturer school of engineering and technology, <br>
 Roles and Responsibilities <br>
1.	Designed course and tutorial questions and programs, wrote assessments, and was responsible for all final grades and marking of students within each semester. 
2.	Provided technical support and resources in curriculum and assessment development within and beyond the university. 
3.	Teach in a variety of settings, from small group tutorials to large lectures, ensuring content, methods of delivery and learning materials meet the defined learning objectives for individual teaching sessions.

Courses Taught: Digital Audio and Video processing, Probability Theory, Machine Learning.
 

## Other Projects:
Master‚Äôs thesis ( Mar-Jul 2017 ): Corpus supported Editing of an erroneous text pattern.<br>
The project aimed at developing a natural language processing model to correct erroneous text patterns to automate generation of sentences from a seed word. In this project, using a dictionary of words as training data, I was able to apply probabilities models and deep neural networks (LSTM) to generate patterns of words to make sentences which are grammatically and semantically correct while minimizing errors.

## üë©üèº‚Äçüéì Education

PhD. Automatique, Signal, Productique, Robotique: (Cotutelle):[Ecole Centrale Nantes](https://www.ls2n.fr/annuaire/Stanley%20MUGISHA/)	_(10/2020 ‚Äì To May 2022)_ <br>
PhD. Mechatronics and Robotics. (Cotutelle):[University of Genova](https://www.dime.unige.it/node/482) 	_(11/2018 ‚Äì ‚Äì To May 2022)_ <br> 
Msc. Computer Science.	Mysore University:	_(06/2015 ‚Äì 08/2017)_ <br>
Bsc Computer Science.	Mbarara University: 	_(07/2008 - 08/2011)_ <br>


## Skills:
1.	Robot kinematics, dynamics, motion planning and control.
2.	Virtual Reality: Unity3D, Unreal, HTC vive system.
3.	Programming: C#, C++ 17, Python 3.8, and MATLAB.
4.	Software Version Control with Git.
5.	System Modelling and Estimation. 
6.	Optimization and Machine learning.
7.	Data Analysis and design of experiments.
8.	Experience with programming collaborative robots (Panda by Franka Emika and the Universal Robot UR5)
<br><br>

## üí¨ Languages

**English**: . Very proficient in speech, reading and writing. <br>
**French**: B1 <br>
**Italian**: B1 
<br><br>

## Selected Research and publications.
1.Guda, V., Mugisha, S., Chevallereau, C., Zoppi, M., Molfino, R., and Chablat, D. (May 6, 2022). "Motion Strategies for a Cobot in a Context of Intermittent Haptic Interface." ASME. J. Mechanisms Robotics. doi: https://doi.org/10.1115/1.4054509<br><br>
2.	Mugisha, S.; Guda, V.K.; Chevallereau, C.; Zoppi, M.; Molfino, R.; Chablat, D. Improving Haptic Response for Contextual Human Robot Interaction. Sensors 2022, 22, 2040. https://doi.org/10.3390/s22052040 <br><br>
3.	Mugisha, S, Zoppi, M, Molfino, R, Guda, V, Chevallereau, C, & Chablat, D. "Safe Collaboration Between Human and Robot in a Context of Intermittent Haptique Interface." Proceedings of the ASME 2021 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference. Volume 8B: 45th Mechanisms and Robotics Conference (MR). Virtual, Online. August 17‚Äì19, 2021. V08BT08A007. ASME. https://doi.org/10.1115/DETC2021-71518 <br><br>
4.	Andreas Gutierrez, Vamsi Guda, Stanley Mugisha, Christine Chevallereau, Damien Chablat,.‚ÄùTrajectory planning in Dynamics Environment : Application for Haptic Perception‚Äù in Safe Human Robot Interaction . 24th international conference on human-computer interaction, Jun 2022, Gothenburg, Sweden <br><br>
